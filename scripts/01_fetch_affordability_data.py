import pandas as pd
import json
import os
import time
from urllib.error import HTTPError

# --- Configuration ---

# This configuration is now more specific, defining the column to use for the
# metric identifier and the measure filter for each dataset independently.
DATASET_CONFIG = {
    "HOUSE_PRICES": {
        "metrics": {"pti": "HPIPTI", "ptr": "HPIPTR", "rent": "RENTIDX"},
        "metric_column": "MEASURE",
        "measure_column": "MEASURE",
        "measure_filter": ["IXOB", "IX"]
    },
    "KEI": {
        "metrics": {"mortgageRate": "IRLTLT01"},
        "metric_column": "MEASURE",
        "measure_column": "MEASURE",
        "measure_filter": ["STSA"]
    },
    "SNA_TABLE4": {
        "metrics": {"income": "B6N"},
        "metric_column": "TRANSACTION",
        "measure_column": "UNIT_MEASURE", # Corrected column for this dataset
        "measure_filter": ["C"]
    }
}

# These are the correct generic column names based on your output.
COLUMN_NAMES = {
    "location": "REF_AREA",
    "frequency": "FREQ",
    "time": "TIME_PERIOD",
    "value": "OBS_VALUE"
}

COUNTRIES = [
  "AUS", "AUT", "BEL", "CAN", "CHL", "COL", "CRI", "CZE", "DNK", "EST",
  "FIN", "FRA", "DEU", "GRC", "HUN", "ISL", "IRL", "ISR", "ITA", "JPN",
  "KOR", "LVA", "LTU", "LUX", "MEX", "NLD", "NZL", "NOR", "POL", "PRT",
  "SVK", "SVN", "ESP", "SWE", "CHE", "TUR", "GBR", "USA",
]

# --- Main Logic ---

def fetch_and_process_data():
    """
    Fetches, processes, and structures data from all configured datasets.
    """
    all_data = {country: {} for country in COUNTRIES}

    for dataset, config in DATASET_CONFIG.items():
        print(f"- Fetching and processing dataset: {dataset}...")
        url = f"https://stats.oecd.org/sdmx-json/data/{dataset}/all/all?contentType=csv"

        try:
            df = pd.read_csv(url)
            
            loc_col = COLUMN_NAMES["location"]
            freq_col = COLUMN_NAMES["frequency"]
            time_col = COLUMN_NAMES["time"]
            value_col = COLUMN_NAMES["value"]
            
            metric_id_col = config["metric_column"]
            measure_filter_col = config["measure_column"]

            df_filtered = df[
                (df[loc_col].isin(COUNTRIES)) &
                (df[metric_id_col].isin(config["metrics"].values())) &
                (df[freq_col] == "A") &
                (df[measure_filter_col].isin(config["measure_filter"]))
            ]

            metric_to_subject = {v: k for k, v in config["metrics"].items()}

            for _, row in df_filtered.iterrows():
                country = row[loc_col]
                metric = metric_to_subject.get(row[metric_id_col])
                year = int(row[time_col])
                value = float(row[value_col])

                if metric not in all_data[country]:
                    all_data[country][metric] = []
                
                all_data[country][metric].append({"year": year, "value": value})

            print(f"  ✓ Successfully processed {dataset}.")

        except HTTPError as e:
            print(f"  - WARNING: Could not download {dataset}. HTTP Error: {e.code}")
        except KeyError as e:
            print(f"  - WARNING: A column name was not found: {e}. The CSV structure may have changed.")
            print(f"    Available columns: {list(df.columns)}")
        except Exception as e:
            print(f"  - WARNING: An unexpected error occurred while processing {dataset}: {e}")
    
        print("  ... Pausing for 5 seconds to be polite to the server.")
        time.sleep(5)
            
    for country_data in all_data.values():
        for metric_data in country_data.values():
            metric_data.sort(key=lambda x: x["year"])
            
    return all_data


def generate_typescript_file(data):
    """
    Generates the TypeScript file content from the final data object.
    """
    data_as_string = json.dumps(data, indent=2)
    return f"""// This file is generated by scripts/01_fetch_affordability_data.py. Do not edit manually.

export type TimeSeriesDataPoint = {{
  readonly year: number;
  readonly value: number;
}};

export type CountryData = {{
  readonly pti: readonly TimeSeriesDataPoint[];
  readonly ptr: readonly TimeSeriesDataPoint[];
  readonly mortgageRate: readonly TimeSeriesDataPoint[];
  readonly income: readonly TimeSeriesDataPoint[];
  readonly rent: readonly TimeSeriesDataPoint[];
}};

export type AffordabilityData = {{
  readonly [countryCode: string]: CountryData;
}};

export const affordabilityData = {data_as_string} as const;
"""

if __name__ == "__main__":
    print("Starting data fetch process using Python and CSV downloads...")
    
    raw_data = fetch_and_process_data()
    
    final_data = {}
    for country, data in raw_data.items():
        if data.get("pti") and data.get("income"):
            final_data[country] = {
                "pti": data.get("pti", []),
                "ptr": data.get("ptr", []),
                "mortgageRate": data.get("mortgageRate", []),
                "income": data.get("income", []),
                "rent": data.get("rent", []),
            }

    if not final_data:
        print("\n❌ No complete data could be fetched. Aborting file generation.")
        exit(1)

    print("\nGenerating TypeScript data file...")
    file_content = generate_typescript_file(final_data)
    
    output_path = os.path.join(os.getcwd(), "data", "affordability.ts")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(file_content)

    countries_found = ", ".join(final_data.keys())
    print(f"✅ Data successfully written to {output_path}")
    print(f"Included countries: {countries_found}")