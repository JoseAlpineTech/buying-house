import pandas as pd
import numpy as np
import json
import os

# --- Configuration ---

# Final configuration based on exhaustive data inspection.
# We will use real house prices, real income, mortgage rates,
# and include the nominal rent price index as requested.
METRIC_CONFIG = {
    "realHousePriceIndex": {"file": "_artifacts/HousingPricesRents.csv", "measure": "RHP"},
    "rentPriceIndex": {"file": "_artifacts/HousingPricesRents.csv", "measure": "RPI"},
    "realIncome": {"file": "_artifacts/Income.csv", "measure": "B6N_R_PPP_P31S14"},
    "mortgageRate": {"file": "_artifacts/MortgageRate.csv", "measure": "IRLT"},
}

# The target year range for the project.
TARGET_YEAR_START = 1985
TARGET_YEAR_END = 2025
TARGET_YEARS = set(range(TARGET_YEAR_START, TARGET_YEAR_END + 1))

COUNTRIES = [
  "AUS", "AUT", "BEL", "CAN", "CHL", "COL", "CRI", "CZE", "DNK", "EST",
  "FIN", "FRA", "DEU", "GRC", "HUN", "ISL", "IRL", "ISR", "ITA", "JPN",
  "KOR", "LVA", "LTU", "LUX", "MEX", "NLD", "NZL", "NOR", "POL", "PRT",
  "SVK", "SVN", "ESP", "SWE", "CHE", "TUR", "GBR", "USA",
]

# --- Data Processing Functions ---

def parse_time_period(series):
    """Converts a time period column (which may be object/string) to integer year."""
    return pd.to_numeric(series.astype(str).str[:4], errors='coerce')

def extrapolate_series(data_points):
    """
    Fills missing years in a time series using interpolation and conservative extrapolation.
    - Interpolates missing years within the known data range.
    - Back-fills years before the first data point with the first available value.
    - Forward-fills years after the last data point with the last available value.
    """
    if not data_points:
        return []

    df = pd.DataFrame(data_points).drop_duplicates(subset='year').set_index('year')
    series = df['value']
    
    # Reindex to the full target year range, creating NaNs for missing years
    series = series.reindex(range(TARGET_YEAR_START, TARGET_YEAR_END + 1))
    
    # 1. Interpolate to fill gaps *between* the first and last valid data points
    series = series.interpolate(method='linear')
    
    # 2. Back-fill and Forward-fill to handle extrapolation at the ends
    # This conservatively carries the earliest and latest known values to the edges of the timeline
    series = series.bfill().ffill()
    
    # Convert back to the desired list of dictionaries format
    final_df = series.reset_index()
    final_df.columns = ['year', 'value']
    final_df['value'] = final_df['value'].round(4)
    
    return final_df.to_dict('records')


def process_files():
    """Reads all CSV files, processes them, and combines them into a single data structure."""
    all_data = {country: {} for country in COUNTRIES}
    loaded_dfs = {}

    for metric, config in METRIC_CONFIG.items():
        file_path = config["file"]
        
        try:
            if file_path not in loaded_dfs:
                if not os.path.exists(file_path):
                    print(f"  - WARNING: File not found: {file_path}. Skipping metric '{metric}'.")
                    continue
                loaded_dfs[file_path] = pd.read_csv(file_path, low_memory=False)
            
            df = loaded_dfs[file_path]
            country_col = 'REF_AREA'

            df_metric = df[
                (df['MEASURE'] == config['measure']) &
                (df[country_col].isin(COUNTRIES))
            ].copy()
            
            df_metric['year'] = parse_time_period(df_metric['TIME_PERIOD'])
            df_metric = df_metric.dropna(subset=['year', 'OBS_VALUE'])
            df_metric['year'] = df_metric['year'].astype(int)

            for country, group in df_metric.groupby(country_col):
                series = group[['year', 'OBS_VALUE']].rename(columns={'OBS_VALUE': 'value'}).to_dict('records')
                series.sort(key=lambda x: x['year'])
                all_data[country][metric] = series
        
        except Exception as e:
            print(f"  - WARNING: An error occurred while processing {metric} from {file_path}: {e}")
            
    return all_data

def generate_typescript_file(data):
    """Generates the TypeScript file content from the final data object."""
    data_as_string = json.dumps(data, indent=2)
    return f"""// This file is generated by scripts/01_fetch_affordability_data.py. Do not edit manually.

export type TimeSeriesDataPoint = {{
  readonly year: number;
  readonly value: number;
}};

export type CountryData = {{
  // Core metrics for a consistent real-vs-real analysis
  readonly realHousePriceIndex: readonly TimeSeriesDataPoint[];
  readonly realIncome: readonly TimeSeriesDataPoint[];
  readonly mortgageRate: readonly TimeSeriesDataPoint[];

  // Nominal rent index. Kept for potential future use or display,
  // but should not be directly compared with real indices.
  readonly rentPriceIndex: readonly TimeSeriesDataPoint[];
}};

export type AffordabilityData = {{
  readonly [countryCode: string]: CountryData;
}};

export const affordabilityData = {data_as_string} as const;
"""

if __name__ == "__main__":
    print("Starting data processing from local CSV files...")
    
    raw_data = process_files()
    
    print("Extrapolating data to fill target range (1985-2025)...")
    final_data = {}
    for country, data in raw_data.items():
        # A country is valid only if it has the core metrics for our real-vs-real analysis.
        if data.get("realHousePriceIndex") and data.get("realIncome"):
            final_data[country] = {}
            for metric in METRIC_CONFIG.keys():
                final_data[country][metric] = extrapolate_series(data.get(metric, []))

    if not final_data:
        print("\n❌ No complete data could be processed. Aborting file generation.")
        print("   Please ensure 'realHousePriceIndex' and 'realIncome' data exist for at least one country.")
        exit(1)

    print("\nGenerating TypeScript data file...")
    file_content = generate_typescript_file(final_data)
    
    output_path = os.path.join(os.getcwd(), "data", "affordability.ts")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(file_content)

    countries_found = ", ".join(sorted(final_data.keys()))
    print(f"✅ Data successfully written to {output_path}")
    print(f"Included countries ({len(final_data.keys())}): {countries_found}")